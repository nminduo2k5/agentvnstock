import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re
import asyncio
from agents.international_underground_news import InternationalUndergroundNewsAgent

class InternationalMarketNews:
    def __init__(self):
        self.name = "International Market News Agent"
        self.description = "Agent for international market news"
        self.source = "CafeF.vn"
        self.cafef_url = "https://cafef.vn/tai-chinh-quoc-te.chn"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.ai_agent = None  # Will be set by main_agent
        self.underground_agent = InternationalUndergroundNewsAgent()
    
    def set_ai_agent(self, ai_agent):
        """Set AI agent for enhanced international news analysis"""
        self.ai_agent = ai_agent
        # Also set AI agent for underground news agent
        self.underground_agent.set_ai_agent(ai_agent)
    
    def get_international_news(self):
        """Láº¥y tin tá»©c thá»‹ trÆ°á»ng quá»‘c táº¿ vá»›i AI analysis"""
        try:
            # Get base international news first
            base_news = None
            
            # Try CafeF first
            cafef_news = self._crawl_cafef_news()
            if cafef_news:
                base_news = {
                    "category": "International Market",
                    "news_count": len(cafef_news),
                    "news": cafef_news,
                    "source": "CafeF.vn"
                }
            else:
                # Fallback to mock international news
                base_news = self._get_international_mock_news()
            
            # Enhance with AI analysis if available
            if base_news and self.ai_agent:
                try:
                    ai_enhancement = self._get_ai_international_analysis(base_news)
                    base_news.update(ai_enhancement)
                except Exception as e:
                    print(f"âš ï¸ AI international analysis failed: {e}")
                    base_news['ai_enhanced'] = False
                    base_news['ai_error'] = str(e)
            
            return base_news

        except Exception as e:
            print(f"âŒ Error crawling CafeF: {e}")
            return self._get_international_mock_news()
    
    def get_market_news(self, category="general", risk_tolerance=50, time_horizon="Trung háº¡n", investment_amount=10000000, **kwargs):
        """Get international market news based on risk profile"""
        return self._get_market_news_impl(category, risk_tolerance, time_horizon, investment_amount)
    
    def _get_market_news_impl(self, category: str = "general", risk_tolerance: int = 50, time_horizon: str = "Trung háº¡n", investment_amount: int = 10000000):
        """Get international market news based on risk profile"""
        try:
            # Get underground news based on risk profile first
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                underground_news = loop.run_until_complete(
                    self.underground_agent.get_underground_news_by_risk_profile(
                        risk_tolerance, time_horizon, investment_amount
                    )
                )
                loop.close()
                
                if not underground_news.get('error'):
                    base_news = {
                        "category": "International Market",
                        "news_count": underground_news['news_count'],
                        "news": underground_news['news'],
                        "source": underground_news['source'],
                        "risk_profile": underground_news['risk_profile'],
                        "news_type": underground_news['news_type'],
                        "recommendation": underground_news.get('recommendation'),
                        "crawl_summary": underground_news.get('crawl_summary')
                    }
                    
                    # Add AI analysis if available
                    if underground_news.get('ai_underground_analysis'):
                        base_news['ai_underground_analysis'] = underground_news['ai_underground_analysis']
                        base_news['ai_enhanced'] = True
                        base_news['market_sentiment'] = underground_news.get('market_sentiment')
                        base_news['risk_assessment'] = underground_news.get('risk_assessment')
                    
                    return base_news
                else:
                    raise Exception("Underground news failed")
                    
            except Exception as e:
                print(f"âš ï¸ Underground news failed: {e}")
                # Fallback to traditional CafeF news
                cafef_news = self._crawl_cafef_news()
                if cafef_news:
                    base_news = {
                        "category": "International Market",
                        "news_count": len(cafef_news),
                        "news": cafef_news,
                        "source": "ðŸ“° CafeF.vn (Tin chÃ­nh thá»‘ng)",
                        "risk_profile": "Default",
                        "news_type": "official"
                    }
                    
                    # Enhance with AI analysis if available
                    if self.ai_agent:
                        try:
                            ai_enhancement = self._get_ai_international_analysis(base_news)
                            base_news.update(ai_enhancement)
                        except Exception as ai_e:
                            print(f"âš ï¸ AI analysis failed: {ai_e}")
                    
                    return base_news
                else:
                    return self._get_international_mock_news()

        except Exception as e:
            print(f"âŒ Error in international market news: {e}")
            return self._get_international_mock_news()

    def _crawl_cafef_news(self):
        try:
            response = requests.get(self.cafef_url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            news_items = []
            
            # Find news articles - multiple selectors
            selectors = [
                '.tlitem',
                '.item-news',
                '.news-item',
                '.article-item',
                'article',
                '.box-category-item'
            ]
            
            articles = []
            for selector in selectors:
                found = soup.select(selector)
                if found:
                    articles = found
                    break
            
            # If no specific selectors work, try finding by common patterns
            if not articles:
                articles = soup.find_all(['div', 'article'], class_=re.compile(r'(news|item|article|post)'))
            
            for article in articles[:20]:  # Limit to 20 articles
                try:
                    # Extract title
                    title_elem = article.find(['h1', 'h2', 'h3', 'h4', 'a'], class_=re.compile(r'(title|headline)'))
                    if not title_elem:
                        title_elem = article.find('a')
                    
                    title = title_elem.get_text(strip=True) if title_elem else "KhÃ´ng cÃ³ tiÃªu Ä‘á»"
                    
                    # Extract link
                    link_elem = title_elem if title_elem and title_elem.name == 'a' else article.find('a')
                    link = link_elem.get('href', '') if link_elem else ''
                    if link and not link.startswith('http'):
                        link = 'https://cafef.vn' + link
                    
                    # Extract time
                    time_elem = article.find(['time', 'span'], class_=re.compile(r'(time|date)'))
                    if not time_elem:
                        time_elem = article.find(text=re.compile(r'\d{1,2}[/\-]\d{1,2}'))
                    
                    published = time_elem.get_text(strip=True) if hasattr(time_elem, 'get_text') else str(time_elem) if time_elem else datetime.now().strftime('%d/%m/%Y')
                    
                    # Extract summary
                    summary_elem = article.find(['p', 'div'], class_=re.compile(r'(summary|desc|content)'))
                    summary = summary_elem.get_text(strip=True)[:200] if summary_elem else title[:100] + "..."
                    
                    if title and len(title) > 10:  # Valid title
                        news_items.append({
                            "title": title,
                            "link": link,
                            "published": published,
                            "summary": summary,
                            "publisher": "CafeF",
                            "source_index": "International Market"
                        })
                        
                except Exception as article_error:
                    continue
            
            print(f"âœ… Crawled {len(news_items)} news from CafeF")
            return news_items
            
        except Exception as e:
            print(f"âŒ CafeF crawling failed: {e}")
            return None

    def _get_international_mock_news(self):
        """Fallback International market news"""
        import random
        
        mock_news = [
            "Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n quá»‘c táº¿ hÃ´m nay cÃ³ nhá»¯ng biáº¿n Ä‘á»™ng máº¡nh",
            "Chá»‰ sá»‘ Dow Jones tÄƒng Ä‘iá»ƒm sau khi cÃ´ng bá»‘ bÃ¡o cÃ¡o kinh táº¿ tÃ­ch cá»±c",
            "Chá»©ng khoÃ¡n chÃ¢u Ã Ä‘á»“ng loáº¡t giáº£m Ä‘iá»ƒm do lo ngáº¡i vá» láº¡m phÃ¡t",
            "GiÃ¡ dáº§u thÃ´ tiáº¿p tá»¥c tÄƒng cao, Ä‘áº¡t má»©c ká»· lá»¥c má»›i",
            "Cá»• phiáº¿u cÃ´ng nghá»‡ Má»¹ phá»¥c há»“i sau Ä‘á»£t bÃ¡n thÃ¡o máº¡nh",
            "NgÃ¢n hÃ ng Trung Æ°Æ¡ng chÃ¢u Ã‚u giá»¯ nguyÃªn lÃ£i suáº¥t trong cuá»™c há»p hÃ´m nay",
            "Thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Nháº­t Báº£n ghi nháº­n má»©c tÄƒng trÆ°á»Ÿng áº¥n tÆ°á»£ng",
            "CÃ¡c nhÃ  Ä‘áº§u tÆ° lo ngáº¡i vá» cÄƒng tháº³ng Ä‘á»‹a chÃ­nh trá»‹ táº¡i Trung ÄÃ´ng",
            "Chá»©ng khoÃ¡n chÃ¢u Ã‚u giáº£m Ä‘iá»ƒm do lo ngáº¡i vá» tÄƒng trÆ°á»Ÿng kinh táº¿",
            "Cá»• phiáº¿u Tesla tiáº¿p tá»¥c tÄƒng máº¡nh sau khi cÃ´ng bá»‘ káº¿t quáº£ kinh doanh tá»‘t"  
        ]
        
        news_items = []
        for i, title in enumerate(mock_news):
            news_items.append({
                "title": title,
                "link": f"https://cafef.vn/mock-news-{i+1}",
                "published": datetime.now().strftime('%d/%m/%Y %H:%M'),
                "summary": f"PhÃ¢n tÃ­ch chi tiáº¿t vá» {title.lower()}",
                "publisher": "CafeF Mock",
                "source_index": "International Market"
            })
        
        return {
            "category": "International Market",
            "news_count": len(news_items),
            "news": news_items,
            "source": "Mock International News"
        }
    
    def _get_ai_international_analysis(self, base_news: dict):
        """Get AI-enhanced international market analysis"""
        try:
            # Prepare international news context for AI analysis
            news_titles = []
            for news_item in base_news.get('news', []):
                news_titles.append(f"- {news_item.get('title', '')}")
            
            news_context = "\n".join(news_titles[:8])  # Limit to top 8 news
            
            context = f"""
PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng tÃ i chÃ­nh quá»‘c táº¿ dá»±a trÃªn tin tá»©c má»›i nháº¥t:

THÃ”NG TIN THá»Š TRÆ¯á»œNG QUá»C Táº¾:
- Danh má»¥c: {base_news.get('category', 'N/A')}
- Sá»‘ lÆ°á»£ng tin: {base_news.get('news_count', 0)}
- Nguá»“n: {base_news.get('source', 'N/A')}

TIN Tá»¨C QUá»C Táº¾:
{news_context}

HÃ£y Ä‘Æ°a ra phÃ¢n tÃ­ch chuyÃªn sÃ¢u vá»:
1. Xu hÆ°á»›ng thá»‹ trÆ°á»ng tÃ i chÃ­nh toÃ n cáº§u
2. TÃ¡c Ä‘á»™ng Ä‘áº¿n thá»‹ trÆ°á»ng chá»©ng khoÃ¡n Viá»‡t Nam
3. CÃ¡c yáº¿u tá»‘ Ä‘á»‹a chÃ­nh trá»‹ vÃ  kinh táº¿ quan trá»ng
4. Dá»± bÃ¡o cho cÃ¡c thá»‹ trÆ°á»ng chÃ­nh (Má»¹, chÃ¢u Ã‚u, chÃ¢u Ã)
5. Khuyáº¿n nghá»‹ Ä‘áº§u tÆ° trong bá»‘i cáº£nh quá»‘c táº¿

Tráº£ lá»i ngáº¯n gá»n, táº­p trung vÃ o nhá»¯ng Ä‘iá»ƒm quan trá»ng nháº¥t.
"""
            
            # Get AI analysis
            ai_result = self.ai_agent.generate_with_fallback(context, 'international_analysis', max_tokens=600)
            
            if ai_result['success']:
                return {
                    'ai_international_analysis': ai_result['response'],
                    'ai_model_used': ai_result['model_used'],
                    'ai_enhanced': True,
                    'global_sentiment': self._extract_global_sentiment(ai_result['response']),
                    'vn_impact': self._extract_vn_impact(ai_result['response'])
                }
            else:
                return {'ai_enhanced': False, 'ai_error': ai_result.get('error', 'AI not available')}
                
        except Exception as e:
            return {'ai_enhanced': False, 'ai_error': str(e)}
    
    def _extract_global_sentiment(self, ai_response: str):
        """Extract global market sentiment from AI response"""
        try:
            ai_lower = ai_response.lower()
            
            # Global sentiment indicators
            positive_indicators = ['tÃ­ch cá»±c', 'positive', 'tÄƒng trÆ°á»Ÿng', 'phá»¥c há»“i', 'á»•n Ä‘á»‹nh']
            negative_indicators = ['tiÃªu cá»±c', 'negative', 'suy thoÃ¡i', 'lo ngáº¡i', 'báº¥t á»•n']
            
            positive_count = sum(1 for indicator in positive_indicators if indicator in ai_lower)
            negative_count = sum(1 for indicator in negative_indicators if indicator in ai_lower)
            
            if positive_count > negative_count:
                return 'POSITIVE'
            elif negative_count > positive_count:
                return 'NEGATIVE'
            else:
                return 'NEUTRAL'
                
        except Exception:
            return 'NEUTRAL'
    
    def _extract_vn_impact(self, ai_response: str):
        """Extract impact on Vietnam market from AI response"""
        try:
            ai_lower = ai_response.lower()
            
            if any(phrase in ai_lower for phrase in ['tÃ¡c Ä‘á»™ng tÃ­ch cá»±c', 'positive impact', 'cÃ³ lá»£i']):
                return 'POSITIVE_IMPACT'
            elif any(phrase in ai_lower for phrase in ['tÃ¡c Ä‘á»™ng tiÃªu cá»±c', 'negative impact', 'báº¥t lá»£i']):
                return 'NEGATIVE_IMPACT'
            elif any(phrase in ai_lower for phrase in ['Ã­t tÃ¡c Ä‘á»™ng', 'limited impact', 'khÃ´ng Ä‘Ã¡ng ká»ƒ']):
                return 'LIMITED_IMPACT'
            else:
                return 'MODERATE_IMPACT'
                
        except Exception:
            return 'MODERATE_IMPACT'